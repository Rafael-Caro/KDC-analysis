{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A preliminary approach to corpus driven research of Persian classical music\n",
    "Babak Nikzat and Rafael Caro Repetto\n",
    "\n",
    "Simple tools for the analysis of the **KUG Dastgāh Corpus** (**KDC**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import essentia\n",
    "import essentia.standard as es\n",
    "import essentiaUtils as eu\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython\n",
    "import intonation\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, specify in the `kdc_folder` variable the path to the `KDC` folder where the **KDC** corpus is locally stored in your computer. By default, the code assumes it is in the parent folder to the one where this notebook is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the KDC folder in the following variable\n",
    "kdc_folder = '../KDC'\n",
    "\n",
    "data_path = os.path.join(kdc_folder, 'KDC-data.csv')\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    kdc_data = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell you can specify which recordings from the **KDC** you would like to analyse. Just include the list of items you would like to study in the `search_items` variable. By default, the code search for the given items in the `Dastgah` column from the `KDC-data.csv` file. If required, a different search criteria can be specified in the `search_column` variable (for example, `Gushe` or `Instrument`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the items to be searched as a list in the following variable\n",
    "search_items = ['Shur']\n",
    "# Specify the category of items to be searched\n",
    "search_column = 'Dastgah'\n",
    "\n",
    "search_column_index = None\n",
    "heading = kdc_data[0].rstrip().split(';')\n",
    "for i in range(len(heading)):\n",
    "    if search_column == heading[i]:\n",
    "        search_column_index = i\n",
    "if search_column_index == None:\n",
    "    print('ERROR: no search column has been found')\n",
    "\n",
    "recordings = {}\n",
    "    \n",
    "for row in kdc_data[1:]:\n",
    "    row_data = row.rstrip().split(';')\n",
    "    if row_data[search_column_index] in search_items:\n",
    "        recording_path = os.path.join(kdc_folder, 'KDC-'+row_data[1], row_data[0])\n",
    "        shahed = row_data[7]\n",
    "        minf0 = row_data[8]\n",
    "        maxf0 = row_data[9]\n",
    "        f0_cf = row_data[10]\n",
    "        if shahed == '':\n",
    "            shahed = None\n",
    "        if minf0 == '':\n",
    "            minf0 = '20'\n",
    "        if maxf0 == '':\n",
    "            maxf0 = '22050'\n",
    "        if f0_cf == '':\n",
    "            f0_cf = '0.9'\n",
    "        recordings[recording_path] = {'shahed': shahed, 'minf0':float(minf0), 'maxf0':float(maxf0), 'f0_cf':float(f0_cf)}\n",
    "\n",
    "print('{} recordings found:'.format(len(recordings)))\n",
    "recordingsPaths = list(recordings.keys())\n",
    "for i in range(len(recordingsPaths)):\n",
    "    print('    {}: {}'.format(i, recordingsPaths[i].split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of single track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute pitch track\n",
    "The pitch track is a necessary step for the computation of pitch histograms, the vibrato analysis and plotting the loudness related figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load audio\n",
    "To select on the recordings retrieved in the previous cell, specify the corresponding index in the following to the variable `recording_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the index to the recording to be analysed in the following variable\n",
    "recording_index = 0\n",
    "\n",
    "recordingPath = recordingsPaths[recording_index]\n",
    "recording = recordings[recordingPath]\n",
    "\n",
    "print(recordingPath.split('/')[-1])\n",
    "\n",
    "IPython.display.Audio(recordingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = es.MonoLoader(filename=recordingPath)\n",
    "eqLoud = es.EqualLoudness()\n",
    "\n",
    "audio = eqLoud(loader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract pitch track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize = 2048\n",
    "hopSize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = eu.get_f0(audio, minf0=recording['minf0'], maxf0=recording['maxf0'], cf=recording['f0_cf'], ws=windowSize, hs=hopSize)\n",
    "timeStamps = np.arange(f0.size)*hopSize/44100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot with spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = eu.spectrogram(audio, ws=windowSize, hs=hopSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the spectrogram might take few minutes. To zoom in to a particular region of the plot, specify a limit to the x and y axes. The start and end values of the limit in each axis should be given as a tuple (for example, `lim_y = (20, 1500)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limits to the x and y axis can be specified in the following variables\n",
    "lim_x = None    # Needs a tuple\n",
    "lim_y = None    # Needs a tuple\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "\n",
    "plt.pcolormesh(x, y, z)\n",
    "plt.plot(timeStamps[f0>0], f0[f0>0], '.k', markersize=0.5)\n",
    "plt.xlim(lim_x)\n",
    "plt.ylim(lim_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute histogram (Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_obj = intonation.Pitch(timeStamps[f0>20], f0[f0>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_obj = intonation.Recording(pitch_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_obj.compute_hist(bins=1000)\n",
    "rec_obj.histogram.get_peaks()\n",
    "rec_obj.histogram.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recordingPath.split('/')[-1])\n",
    "print()\n",
    "\n",
    "peaks = rec_obj.histogram.peaks['peaks']\n",
    "for i in range(len(peaks[0])):\n",
    "    print('{}. {} : {:.6f}'.format(i, round(peaks[0][i]), peaks[1][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute histogram (cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shahed = recording['shahed']\n",
    "one_octave = False\n",
    "\n",
    "if shahed == None:\n",
    "    print('ERROR: There is no shahed computed for this recording')\n",
    "else:\n",
    "    print('Shahed for {}: {}'.format(recordingPath.split('/')[-1], shahed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0cents = 1200 * np.log2(f0[f0>0] / float(shahed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_cents_obj = intonation.Pitch(timeStamps[f0>0], f0cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_cents_obj = intonation.Recording(pitch_cents_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_cents_obj.compute_hist(bins=1200, folded=one_octave)\n",
    "rec_cents_obj.histogram.get_peaks()\n",
    "rec_cents_obj.histogram.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recordingPath.split('/')[-1])\n",
    "print()\n",
    "\n",
    "if one_octave:\n",
    "    print('   0 : {:.6f}'.format(rec_cents_obj.histogram.y[0]))\n",
    "\n",
    "peaks_cents = rec_cents_obj.histogram.peaks['peaks']\n",
    "for i in range(len(peaks_cents[0])):\n",
    "    print('{}. {} : {:.6f}'.format(i, round(peaks_cents[0][i]), peaks_cents[1][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vibrato analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vib = es.Vibrato(sampleRate = 44100/hopSize)\n",
    "vibF, vibE = vib(essentia.array(f0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To zoom in to a particular region of the plot, specify a limit to the x and y axes. The start and end values of the limit in each axis should be given as a tuple (for example, `lim_x = (0, 10)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limits to the x and y axes can be specified in the following variables\n",
    "lim_x = None    # Needs a tuple\n",
    "lim_y = None    # Needs a tuple\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(311)\n",
    "plt.plot(timeStamps[f0>0], f0[f0>0], '.k', markersize=0.5)\n",
    "plt.xlim(lim_x)\n",
    "plt.ylim(lim_y)\n",
    "plt.title('f0')\n",
    "plt.subplot(312)\n",
    "plt.plot(timeStamps, vibF)\n",
    "plt.xlim(lim_x)\n",
    "plt.title('frequency')\n",
    "plt.subplot(313)\n",
    "plt.plot(timeStamps, vibE)\n",
    "plt.xlim(lim_x)\n",
    "plt.title('extent')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recordingPath.split('/')[-1])\n",
    "print()\n",
    "\n",
    "freq_mean = np.mean(vibF[vibF>0])\n",
    "freq_sd = np.std(vibF[vibF>0])\n",
    "print('Frequency:\\tmean: {:.2f} Hz\\t\\tSD: {:.2f} Hz'.format(freq_mean, freq_sd))\n",
    "\n",
    "ex_mean = np.mean(vibE[vibE>20])\n",
    "ex_sd = np.std(vibE[vibE>20])\n",
    "print('Extent:\\t\\tmean: {:.2f} cents\\tSD: {:.2f} cents'.format(ex_mean, ex_sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loudness analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loud = es.Loudness()\n",
    "energy = es.Energy()\n",
    "rms = es.RMS()\n",
    "\n",
    "loudTrack = []\n",
    "energyTrack = []\n",
    "rmsTrack = []\n",
    "\n",
    "for frame in es.FrameGenerator(audio, frameSize=2048, hopSize=hopSize):\n",
    "    frameLoud = loud(frame)\n",
    "    frameEnergy = energy(frame)\n",
    "    frameRms = rms(frame)\n",
    "    loudTrack.append(frameLoud)\n",
    "    energyTrack.append(frameEnergy)\n",
    "    rmsTrack.append(frameRms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim_x = None       # Needs a tuple\n",
    "lim_y = None         # Needs a tuple\n",
    "lim_y_loud = None    # Needs a tuple\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(411)\n",
    "plt.plot(timeStamps, f0, '.k', markersize=0.5)\n",
    "plt.xlim(lim_x)\n",
    "plt.ylim(lim_y)\n",
    "plt.title('pitch')\n",
    "plt.subplot(412)\n",
    "plt.plot(timeStamps, loudTrack)\n",
    "plt.xlim(lim_x)\n",
    "plt.ylim(lim_y_loud)\n",
    "plt.title('loudness (Loudness)')\n",
    "plt.subplot(413)\n",
    "plt.plot(timeStamps, energyTrack)\n",
    "plt.xlim(lim_x)\n",
    "plt.ylim(lim_y_loud)\n",
    "plt.title('loudness (Energy)')\n",
    "plt.subplot(414)\n",
    "plt.plot(timeStamps, rmsTrack)\n",
    "plt.xlim(lim_x)\n",
    "plt.ylim(lim_y_loud)\n",
    "plt.title('loudness (RMS)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start and end analysis\n",
    "This block of code retrives the pitch value of the first note of the given pitch track, the pitch value of the first note that lasts longer than 1 second, and the pitch value of the last note, and compares them with the pitch value of the recording's *shahed*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitchContourSegmentation = es.PitchContourSegmentation()\n",
    "\n",
    "midiNotes = pitchContourSegmentation(essentia.array(f0), audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To dump the retrieve notes to a text file, so that it can be used in other software, like Sonic Visualiser, change the `print_notes` variable to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the following variable to True in order to dump the notes returned in the previous cell to a text file\n",
    "print_notes = False\n",
    "\n",
    "if print_notes:\n",
    "    txt = ''\n",
    "    for i in range(len(midiNotes[0])):\n",
    "        txt += str(midiNotes[0][i]) + '\\t' + str(midiNotes[1][i]) + '\\t' + midi2Hz(midiNotes[2][i]) + '\\n'\n",
    "\n",
    "    with open(recordingPath[:-5]+'-notes.txt', 'w') as f:\n",
    "        f.write(txt.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi2Hz(midi):\n",
    "    '''\n",
    "    Converts a given midi value to its equivalent in hertz\n",
    "    \n",
    "    Args:\n",
    "        midi (str): midi value as string\n",
    "        \n",
    "    Returns:\n",
    "        frequency (str): equivalent frequency in Hertz as string\n",
    "        \n",
    "    >>> midi2Hz('60')\n",
    "    '261.6255653005986'\n",
    "    '''\n",
    "    f = 2 ** ((float(midi) - 69) / 12.) * 440\n",
    "    return str(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('{:.2f}: {:.2f}'.format(midiNotes[1][i], midiNotes[2][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_start = midiNotes[0][0]\n",
    "first_end = first_start + midiNotes[1][0]\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "dur = midiNotes[1][0]\n",
    "while dur < 1:\n",
    "    i += 1\n",
    "    j = 0\n",
    "    dur = midiNotes[1][i]\n",
    "    midi = midiNotes[2][i]\n",
    "    while midiNotes[2][i+j+1] == midi:\n",
    "        dur += midiNotes[1][i+j+1]\n",
    "        j += 1\n",
    "first_long_start = midiNotes[0][i]\n",
    "first_long_end = first_long_start + dur\n",
    "\n",
    "last_start = midiNotes[0][-1]\n",
    "last_end = last_start + midiNotes[1][-1]\n",
    "\n",
    "first_start_i = np.abs(timeStamps - first_start).argmin()\n",
    "first_end_i = np.abs(timeStamps - first_end).argmin()\n",
    "\n",
    "first_long_start_i = np.abs(timeStamps - first_long_start).argmin()\n",
    "first_long_end_i = np.abs(timeStamps - first_long_end).argmin()\n",
    "\n",
    "last_start_i = np.abs(timeStamps - last_start).argmin()\n",
    "last_end_i = np.abs(timeStamps - last_end).argmin()\n",
    "\n",
    "first = f0[first_start_i:first_end_i+1]\n",
    "first_long = f0[first_long_start_i:first_long_end_i+1]\n",
    "last = f0[last_start_i:last_end_i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(311)\n",
    "plt.plot(timeStamps[first_start_i:first_end_i+1], first)\n",
    "plt.h\n",
    "plt.title('first')\n",
    "plt.subplot(312)\n",
    "plt.plot(timeStamps[first_long_start_i:first_long_end_i+1], first_long)\n",
    "plt.title('first long')\n",
    "plt.subplot(313)\n",
    "plt.plot(timeStamps[last_start_i:last_end_i+1], last)\n",
    "plt.title('last')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recordingPath.split('/')[-1])\n",
    "print('Shahed: {}'.format(recording['shahed']))\n",
    "print('First note (mean): {}'.format(round(np.mean(first))))\n",
    "print('First long note (mean): {}'.format(round(np.mean(first_long))))\n",
    "print('Last note (mean): {}'.format(round(np.mean(last))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of multiple recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select recordings\n",
    "Give the list of **indexes** of the recordings resulting from the third cell of this notebook. If no index is given, all those recordings will be selected by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the indexes of the recordings to be analysed in the following list. If none is given, all recordings are selected.\n",
    "selected_indexes = []\n",
    "\n",
    "selected_recordings = {}\n",
    "\n",
    "if len(selected_indexes) == 0:\n",
    "    selected_indexes = range(len(recordings.keys()))\n",
    "    \n",
    "for i in range(len(selected_indexes)):\n",
    "    recordingPath = recordingsPaths[i]\n",
    "    recording = recordings[recordingPath]\n",
    "    if recording['shahed'] == None:\n",
    "        print('The recording {} has no shahed: it is not selected'.format(recordingPath.split('/')[-1]))\n",
    "    else:\n",
    "        selected_recordings[recordingPath] = recording\n",
    "\n",
    "print()\n",
    "print('{} recordings selected:'.format(len(selected_recordings)))\n",
    "for k in selected_recordings.keys():\n",
    "    print('    {}'.format(k.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated pitch track (cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize = 2048\n",
    "hopSize = 128\n",
    "\n",
    "eqLoud = es.EqualLoudness()\n",
    "\n",
    "agg_f0_cents = np.array([])\n",
    "\n",
    "for k in selected_recordings.keys():\n",
    "    recording = selected_recordings[k]\n",
    "    loader = es.MonoLoader(filename=k)\n",
    "    print('Loading {}'.format(k.split('/')[-1]))\n",
    "    audio = eqLoud(loader())\n",
    "    f0 = eu.get_f0(audio, minf0=recording['minf0'], maxf0=recording['maxf0'], cf=recording['f0_cf'], ws=windowSize, hs=hopSize)\n",
    "    f0cents = 1200 * np.log2(f0[f0>0] / float(recording['shahed']))\n",
    "    agg_f0_cents = np.append(agg_f0_cents, f0cents)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated pitch histogram (cents)\n",
    "\n",
    "To fold the pitch histogram to a single octave, change the value of the `one_octave` variable to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the value of the following variable to True in order to fold the pitch histogram to one octave\n",
    "one_octave=False\n",
    "\n",
    "agg_pitch_cents_obj = intonation.Pitch(np.arange(len(agg_f0_cents[agg_f0_cents>0])), agg_f0_cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_rec_cents_obj = intonation.Recording(agg_pitch_cents_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_rec_cents_obj.compute_hist(bins=1200, folded=one_octave)\n",
    "agg_rec_cents_obj.histogram.get_peaks()\n",
    "agg_rec_cents_obj.histogram.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if one_octave:\n",
    "    print('   0 : {:.6f}'.format(agg_rec_cents_obj.histogram.y[0]))\n",
    "\n",
    "agg_peaks_cents = agg_rec_cents_obj.histogram.peaks['peaks']\n",
    "for i in range(len(agg_peaks_cents[0])):\n",
    "    print('{}. {} : {:.6f}'.format(i, round(agg_peaks_cents[0][i]), agg_peaks_cents[1][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start and end analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi2Hz(midi):\n",
    "    '''\n",
    "    Converts a given midi value to its equivalent in hertz\n",
    "    \n",
    "    Args:\n",
    "        midi (str): midi value as string\n",
    "        \n",
    "    Returns:\n",
    "        frequency (str): equivalent frequency in Hertz as string\n",
    "        \n",
    "    >>> midi2Hz('60')\n",
    "    '261.6255653005986'\n",
    "    '''\n",
    "    f = 2 ** ((float(midi) - 69) / 12.) * 440\n",
    "    return str(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize = 2048\n",
    "hopSize = 128\n",
    "\n",
    "eqLoud = es.EqualLoudness()\n",
    "pitchContourSegmentation = es.PitchContourSegmentation()\n",
    "\n",
    "message = 'Recording\\t\\tShahed\\t\\tFirst note\\tFirst long note\\t\\tLast note\\n'\n",
    "\n",
    "for  k in selected_recordings.keys():\n",
    "    message += k.split('/')[-1]\n",
    "    recording = selected_recordings[k]\n",
    "    if len(k.split('/')[-1]) > 15:\n",
    "        sep = '\\t '\n",
    "    else:\n",
    "        sep = '\\t\\t '\n",
    "    message += sep + selected_recordings[k]['shahed'] + '\\t\\t '\n",
    "    loader = es.MonoLoader(filename=k)\n",
    "    print('Loading {}'.format(k.split('/')[-1]))\n",
    "    audio = eqLoud(loader())\n",
    "\n",
    "    print('  Computing pitch track...')\n",
    "    f0 = eu.get_f0(audio, minf0=recording['minf0'], maxf0=recording['maxf0'], cf=recording['f0_cf'], ws=windowSize, hs=hopSize)\n",
    "\n",
    "    print('  Computing notes...')\n",
    "    midiNotes = pitchContourSegmentation(essentia.array(f0), audio)\n",
    "\n",
    "    first_start = midiNotes[0][0]\n",
    "    first_end = first_start + midiNotes[1][0]\n",
    "    i = 0\n",
    "    j = 0\n",
    "    dur = midiNotes[1][0]\n",
    "    while dur < 1:\n",
    "        i += 1\n",
    "        j = 0\n",
    "        dur = midiNotes[1][i]\n",
    "        midi = midiNotes[2][i]\n",
    "        while midiNotes[2][i+j+1] == midi:\n",
    "            dur += midiNotes[1][i+j+1]\n",
    "            j += 1\n",
    "    first_long_start = midiNotes[0][i]\n",
    "    first_long_end = first_long_start + dur\n",
    "\n",
    "    last_start = midiNotes[0][-1]\n",
    "    last_end = last_start + midiNotes[1][-1]\n",
    "\n",
    "    first_start_i = np.abs(timeStamps - first_start).argmin()\n",
    "    first_end_i = np.abs(timeStamps - first_end).argmin()\n",
    "\n",
    "    first_long_start_i = np.abs(timeStamps - first_long_start).argmin()\n",
    "    first_long_end_i = np.abs(timeStamps - first_long_end).argmin()\n",
    "\n",
    "    last_start_i = np.abs(timeStamps - last_start).argmin()\n",
    "    last_end_i = np.abs(timeStamps - last_end).argmin()\n",
    "\n",
    "    first = f0[first_start_i:first_end_i+1]\n",
    "    first_long = f0[first_long_start_i:first_long_end_i+1]\n",
    "    last = f0[last_start_i:last_end_i+1]\n",
    "    \n",
    "    message += str(round(np.mean(first))) + '\\t\\t ' + str(round(np.mean(first_long))) + '\\t\\t\\t ' + str(round(np.mean(last))) + '\\n'\n",
    "\n",
    "print()\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find pitch range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_index = 3\n",
    "\n",
    "recordingPath = recordingsPaths[recording_index]\n",
    "recording = recordings[recordingPath]\n",
    "\n",
    "print(recordingPath.split('/')[-1])\n",
    "\n",
    "IPython.display.Audio(recordingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = es.MonoLoader(filename=recordingPath)\n",
    "eqLoud = es.EqualLoudness()\n",
    "\n",
    "audio = eqLoud(loader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract pitch track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize = 2048\n",
    "hopSize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in recording:\n",
    "    print(k + ': ' + str(recording[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = eu.get_f0(audio, minf0=130, maxf0=300, cf=0.5, ws=windowSize, hs=hopSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.floor(min(f0[f0>0])))\n",
    "print(np.ceil(max(f0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = ''\n",
    "for i in f0:\n",
    "    txt += str(i) + '\\n'\n",
    "\n",
    "with open(recordingPath[:-5]+'-f0.txt', 'w') as f:\n",
    "    f.write(txt.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot with spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = eu.spectrogram(audio, ws=windowSize, hs=hopSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 6)\n",
    "\n",
    "plt.pcolormesh(x, y, z)\n",
    "plt.plot(x[f0>20], f0[f0>20], '.k', markersize=0.5)\n",
    "plt.ylim([0, 1500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate pitch track for the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize = 2048\n",
    "hopSize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_folder = os.path.join(kdc_folder, 'pitchTracks')\n",
    "try:\n",
    "    os.mkdir(pt_folder)\n",
    "    os.mkdir(os.path.join(pt_folder, 'KDC-CR'))\n",
    "    os.mkdir(os.path.join(pt_folder, 'KDC-OR'))\n",
    "except:\n",
    "    print('(The pitch track folder already exists)\\n')\n",
    "\n",
    "for row in kdc_data[1:]:\n",
    "    # Process data\n",
    "    row_data = row.rstrip().split(';')\n",
    "    col_folder = 'KDC-'+row_data[1]\n",
    "    filename = row_data[0]\n",
    "    print('Processing KDC-{}/{}'.format(col_folder, filename))\n",
    "    recording_path = os.path.join(kdc_folder, col_folder, filename)\n",
    "    minf0 = row_data[8]\n",
    "    maxf0 = row_data[9]\n",
    "    f0_cf = row_data[10]\n",
    "    print('\\tMinf0: {}\\tMaxf0: {}\\tf0_cf: {}'.format(minf0, maxf0, f0_cf))\n",
    "    # Compute pitchtrack\n",
    "    f0 = eu.get_f0(audio, minf0=130, maxf0=300, cf=0.5, ws=windowSize, hs=hopSize)\n",
    "    # Save pitchtrack file\n",
    "    f0_txt = ''\n",
    "    f0_file = os.path.join(pt_folder, col_folder, filename[:-5]+'-f0.txt')\n",
    "    for i in f0:\n",
    "        f0_txt += str(i) + '\\n'\n",
    "    with open(f0_file, 'w') as f:\n",
    "        f.write(f0_txt.rstrip())\n",
    "    print('\\tDone!')\n",
    "print('\\nAll files computed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
